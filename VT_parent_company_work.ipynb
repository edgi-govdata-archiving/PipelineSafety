{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ashok\\documents\\github\\pipelinesafety\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# library installations if necessary, make sure you're using .venv!\n",
    "\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e90b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHMSA distinct cpf_key count: 4944\n",
      "GJF rows with extracted cpf_key: 718\n",
      "Matched rows: 667\n",
      "Unmatched GJF rows after cpf merge: 53\n"
     ]
    }
   ],
   "source": [
    "vt = pd.read_excel(\"ViolationTracker_21Aug2025_PHMSA_only.xlsx\")\n",
    "phmsa = pd.read_excel(\"PHMSA_RAW_DATA.xlsx\")\n",
    "\n",
    "# Helper function to make a numeric-only CPF key for PHMSA (e.g., \"42025041NOA\" -> \"42025041\")\n",
    "def phmsa_cpf_key(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    m = re.match(r'\\D*(\\d+)', str(s))\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "phmsa[\"cpf_key\"] = phmsa[\"CPF_Number\"].apply(phmsa_cpf_key)\n",
    "\n",
    "# Helper function that extracts CPF number from \"info_source\" column in GJF data.\n",
    "# Try pattern 'cpf_123456789' first, else fallback to the longest digit run\n",
    "def vt_cpf_from_info(url):\n",
    "    if pd.isna(url):\n",
    "        return \"\"\n",
    "    txt = str(url)\n",
    "    # This regex matches things like 'cpf_12345' or 'CPF-12345'\n",
    "    m = re.search(r'(?i)cpf[_\\-]?(\\d{4,})', txt)   # case-insensitive, require >=4 digits\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    # fallback: find all digit runs and return the longest (likely the CPF if present)\n",
    "    runs = re.findall(r'(\\d{4,})', txt)   # capture runs of 4+ digits\n",
    "    if not runs:\n",
    "        return \"\"\n",
    "    # choose the longest run (if ties, first)\n",
    "    runs_sorted = sorted(runs, key=lambda x: (-len(x), x))\n",
    "    return runs_sorted[0]\n",
    "\n",
    "vt[\"cpf_key_extracted\"] = vt[\"info_source\"].apply(vt_cpf_from_info)\n",
    "\n",
    "# 3) Quick sanity counts\n",
    "print(\"PHMSA distinct cpf_key count:\", phmsa[\"cpf_key\"].nunique())\n",
    "print(\"GJF rows with extracted cpf_key:\", (vt[\"cpf_key_extracted\"] != \"\").sum())\n",
    "\n",
    "# 4) Merge VT -> PHMSA on the cpf key\n",
    "merged = vt.merge(phmsa, left_on=\"cpf_key_extracted\", right_on=\"cpf_key\", how=\"left\", suffixes=(\"_vt\", \"_phmsa\"))\n",
    "\n",
    "# 5) Inspect mismatches\n",
    "matched = merged[merged[\"CPF_Number\"].notna()]\n",
    "unmatched = merged[merged[\"CPF_Number\"].isna()]\n",
    "print(\"Matched rows:\", len(matched))\n",
    "print(\"Unmatched GJF rows after cpf merge:\", len(unmatched))\n",
    "\n",
    "# Save a sample of merged/unmatched for inspection\n",
    "# merged.to_excel(\"VT_PHMSA_merged_by_cpf.xlsx\", index=False)\n",
    "# unmatched.to_excel(\"unmatched_rows.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421dbef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_changed\n",
      "False    475\n",
      "True     192\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashok\\AppData\\Local\\Temp\\ipykernel_27624\\563850408.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched[\"current_parent_name_n\"] = matched[\"current_parent_name\"].apply(normalize_parent)\n",
      "C:\\Users\\Ashok\\AppData\\Local\\Temp\\ipykernel_27624\\563850408.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched[\"reporting_date_parent_n\"] = matched[\"reporting_date_parent\"].apply(normalize_parent)\n",
      "C:\\Users\\Ashok\\AppData\\Local\\Temp\\ipykernel_27624\\563850408.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched[\"parent_changed\"] = matched[\"current_parent_name_n\"] != matched[\"reporting_date_parent_n\"]\n"
     ]
    }
   ],
   "source": [
    "# Helper to normalize parent name\n",
    "def normalize_parent(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    return re.sub(r'[^a-z0-9 ]', '', str(name).lower().strip())\n",
    "\n",
    "# New columns for normalized names\n",
    "matched[\"current_parent_name_n\"] = matched[\"current_parent_name\"].apply(normalize_parent)\n",
    "matched[\"reporting_date_parent_n\"] = matched[\"reporting_date_parent\"].apply(normalize_parent)\n",
    "\n",
    "# parent_changed is either True or False\n",
    "matched[\"parent_changed\"] = matched[\"current_parent_name_n\"] != matched[\"reporting_date_parent_n\"]\n",
    "\n",
    "# Check counts\n",
    "print(matched[\"parent_changed\"].value_counts())\n",
    "\n",
    "# Save to file for inspection\n",
    "# matched.to_excel(\"VT_PHMSA_matched_with_parentchange.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "HISTORY RECAP:\n",
      "Berkshire Hathaway acquired Dominion Energy Transmission, Inc. in November 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashok\\AppData\\Local\\Temp\\ipykernel_27624\\1303916294.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched[\"acquisition_exact_date\"] = None\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is named `matched`\n",
    "recap_to_date = {}  # cache dictionary\n",
    "\n",
    "# Ensure the column exists even if some rows are blank\n",
    "matched[\"acquisition_exact_date\"] = None\n",
    "\n",
    "# Iterate through unique, non-null recaps\n",
    "unique_recaps = matched[\"history_recap\"].dropna().unique()\n",
    "\n",
    "for recap in unique_recaps:\n",
    "    # Skip if we've already stored this one\n",
    "    if recap in recap_to_date:\n",
    "        continue\n",
    "\n",
    "    print(\"\\n-----------------------------\")\n",
    "    print(f\"HISTORY RECAP:\\n{recap}\")\n",
    "    date_input = input(\"Enter the exact acquisition/merger date (MM/DD/YYYY), or press Enter to skip: \").strip()\n",
    "\n",
    "    if date_input:\n",
    "        recap_to_date[recap] = date_input\n",
    "    else:\n",
    "        recap_to_date[recap] = None  # mark as skipped\n",
    "\n",
    "# Apply to dataframe\n",
    "matched[\"acquisition_exact_date\"] = matched[\"history_recap\"].map(recap_to_date)\n",
    "\n",
    "# Save interim results\n",
    "matched.to_excel(\"VT_PHMSA_with_acquisition_dates.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Done. Saved file with 'acquisition_exact_date' column.\")\n",
    "print(f\"Total unique recaps processed: {len(recap_to_date)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
